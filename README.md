# Transformer
Use git lfs to clone with weights
## Fastest OpenCL GPT-2 (124M) inference*
- [ ] Fastest Inference

- [X] Support for all GPT-2 Models

- [ ] Remove all Numpy Usage

- [ ] Support for any transformer

- [ ] Support other compute languages

- [ ] Refactor to library
