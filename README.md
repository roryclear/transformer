# Transformer
Use git lfs to clone with weights
## Fastest OpenCL GPT-2 (124M) inference*
- [x] Fastest Inference*

- [ ] Remove all Numpy Usage

- [ ] Support for any transformer

- [ ] Support other compute languages

- [ ] Refactor to library

  

*fastest GPT-2 124M inference I can find, running on my laptop (2020 XPS13). Almost 50% faster than huggingface's Transformers.
